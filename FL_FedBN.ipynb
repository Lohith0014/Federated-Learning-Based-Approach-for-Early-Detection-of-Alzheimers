{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f475f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Federated Learning with FedBN ===\n",
      "Running 10 rounds with 5 epochs per client\n",
      "ğŸ” Loading client datasets...\n",
      "Found 21960 images belonging to 2 classes.\n",
      "Found 5490 images belonging to 2 classes.\n",
      "\n",
      "Client 0 Data:\n",
      "Training samples: 21960\n",
      "Validation samples: 5490\n",
      "Class distribution: {'Demented': 0, 'Non Demented': 1}\n",
      "Found 21960 images belonging to 2 classes.\n",
      "Found 5490 images belonging to 2 classes.\n",
      "\n",
      "Client 1 Data:\n",
      "Training samples: 21960\n",
      "Validation samples: 5490\n",
      "Class distribution: {'Demented': 0, 'Non Demented': 1}\n",
      "Found 21960 images belonging to 2 classes.\n",
      "Found 5490 images belonging to 2 classes.\n",
      "\n",
      "Client 2 Data:\n",
      "Training samples: 21960\n",
      "Validation samples: 5490\n",
      "Class distribution: {'Demented': 0, 'Non Demented': 1}\n",
      "Found 21960 images belonging to 2 classes.\n",
      "Found 5490 images belonging to 2 classes.\n",
      "\n",
      "Client 3 Data:\n",
      "Training samples: 21960\n",
      "Validation samples: 5490\n",
      "Class distribution: {'Demented': 0, 'Non Demented': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline - Accuracy: 0.5000, AUC: 0.5140\n",
      "\n",
      "=== Round 1/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 425ms/step - accuracy: 0.4997 - loss: 0.6933 - val_accuracy: 1.0000 - val_loss: 0.6866\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 407ms/step - accuracy: 0.5262 - loss: 0.6928 - val_accuracy: 0.0000e+00 - val_loss: 0.7178\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 402ms/step - accuracy: 0.5173 - loss: 0.6920 - val_accuracy: 0.0000e+00 - val_loss: 0.7083\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 381ms/step - accuracy: 0.4926 - loss: 0.6927 - val_accuracy: 0.0000e+00 - val_loss: 0.7130\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 334ms/step - accuracy: 0.5252 - loss: 0.6905 - val_accuracy: 0.6906 - val_loss: 0.6883\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 435ms/step - accuracy: 0.5007 - loss: 0.6938 - val_accuracy: 0.1906 - val_loss: 0.6953\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 418ms/step - accuracy: 0.5363 - loss: 0.6920 - val_accuracy: 0.0000e+00 - val_loss: 0.7438\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 405ms/step - accuracy: 0.5145 - loss: 0.6923 - val_accuracy: 0.0000e+00 - val_loss: 0.7435\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.5132 - loss: 0.6911 - val_accuracy: 0.1547 - val_loss: 0.7077\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 337ms/step - accuracy: 0.5377 - loss: 0.6904 - val_accuracy: 0.7109 - val_loss: 0.6668\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.5094 - loss: 0.6925 - val_accuracy: 0.0000e+00 - val_loss: 0.7380\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 419ms/step - accuracy: 0.5001 - loss: 0.6925 - val_accuracy: 0.0000e+00 - val_loss: 0.7523\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.5097 - loss: 0.6910 - val_accuracy: 0.1484 - val_loss: 0.7019\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.5110 - loss: 0.6903 - val_accuracy: 0.0109 - val_loss: 0.7291\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 339ms/step - accuracy: 0.5290 - loss: 0.6891 - val_accuracy: 0.2953 - val_loss: 0.7061\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.4849 - loss: 0.6938 - val_accuracy: 0.0000e+00 - val_loss: 0.7068\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 417ms/step - accuracy: 0.4948 - loss: 0.6922 - val_accuracy: 0.0000e+00 - val_loss: 0.7173\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 407ms/step - accuracy: 0.5359 - loss: 0.6921 - val_accuracy: 0.0000e+00 - val_loss: 0.7174\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.5125 - loss: 0.6916 - val_accuracy: 0.7859 - val_loss: 0.6843\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 333ms/step - accuracy: 0.5276 - loss: 0.6910 - val_accuracy: 0.7109 - val_loss: 0.6619\n",
      "\n",
      "Round 1 Results:\n",
      "Validation Accuracy: 0.5182\n",
      "Validation AUC: 0.6303\n",
      "\n",
      "=== Round 2/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 433ms/step - accuracy: 0.5412 - loss: 0.6891 - val_accuracy: 0.7594 - val_loss: 0.6801\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 445ms/step - accuracy: 0.5484 - loss: 0.6862 - val_accuracy: 0.4609 - val_loss: 0.7001\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 430ms/step - accuracy: 0.5484 - loss: 0.6858 - val_accuracy: 0.8562 - val_loss: 0.6578\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 388ms/step - accuracy: 0.5885 - loss: 0.6835 - val_accuracy: 0.9984 - val_loss: 0.5975\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.5146 - loss: 0.6902 - val_accuracy: 0.3562 - val_loss: 0.7103\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 444ms/step - accuracy: 0.5535 - loss: 0.6894 - val_accuracy: 0.9812 - val_loss: 0.6527\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426ms/step - accuracy: 0.6152 - loss: 0.6841 - val_accuracy: 0.0000e+00 - val_loss: 0.8138\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 415ms/step - accuracy: 0.5458 - loss: 0.6830 - val_accuracy: 0.5453 - val_loss: 0.6900\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389ms/step - accuracy: 0.5721 - loss: 0.6831 - val_accuracy: 0.5156 - val_loss: 0.6962\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.6083 - loss: 0.6767 - val_accuracy: 0.6891 - val_loss: 0.6600\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 444ms/step - accuracy: 0.5284 - loss: 0.6902 - val_accuracy: 0.3281 - val_loss: 0.7047\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 420ms/step - accuracy: 0.5377 - loss: 0.6875 - val_accuracy: 0.9703 - val_loss: 0.6542\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.5493 - loss: 0.6858 - val_accuracy: 0.8813 - val_loss: 0.6594\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 391ms/step - accuracy: 0.5628 - loss: 0.6854 - val_accuracy: 0.9922 - val_loss: 0.6099\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.5404 - loss: 0.6863 - val_accuracy: 0.4062 - val_loss: 0.7013\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 0.5598 - loss: 0.6893 - val_accuracy: 0.4125 - val_loss: 0.7017\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 428ms/step - accuracy: 0.5380 - loss: 0.6873 - val_accuracy: 0.0000e+00 - val_loss: 0.8015\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 422ms/step - accuracy: 0.5441 - loss: 0.6869 - val_accuracy: 0.9719 - val_loss: 0.6292\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 397ms/step - accuracy: 0.5695 - loss: 0.6847 - val_accuracy: 0.7328 - val_loss: 0.6609\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.5725 - loss: 0.6781 - val_accuracy: 0.5500 - val_loss: 0.6847\n",
      "\n",
      "Round 2 Results:\n",
      "Validation Accuracy: 0.6009\n",
      "Validation AUC: 0.6477\n",
      "\n",
      "=== Round 3/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 440ms/step - accuracy: 0.6065 - loss: 0.6782 - val_accuracy: 0.8281 - val_loss: 0.6353\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 425ms/step - accuracy: 0.5945 - loss: 0.6732 - val_accuracy: 0.4734 - val_loss: 0.7145\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 413ms/step - accuracy: 0.5960 - loss: 0.6682 - val_accuracy: 0.5594 - val_loss: 0.6911\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.5908 - loss: 0.6705 - val_accuracy: 0.3578 - val_loss: 0.7547\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - accuracy: 0.6138 - loss: 0.6624 - val_accuracy: 0.3719 - val_loss: 0.7399\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 442ms/step - accuracy: 0.6010 - loss: 0.6744 - val_accuracy: 0.8859 - val_loss: 0.6091\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 425ms/step - accuracy: 0.5912 - loss: 0.6762 - val_accuracy: 0.4187 - val_loss: 0.7320\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408ms/step - accuracy: 0.6113 - loss: 0.6710 - val_accuracy: 0.6859 - val_loss: 0.6594\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 388ms/step - accuracy: 0.5947 - loss: 0.6678 - val_accuracy: 0.4953 - val_loss: 0.7123\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.6000 - loss: 0.6663 - val_accuracy: 0.4281 - val_loss: 0.7250\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 442ms/step - accuracy: 0.5677 - loss: 0.6826 - val_accuracy: 0.3031 - val_loss: 0.7464\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.5816 - loss: 0.6818 - val_accuracy: 0.7203 - val_loss: 0.6547\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 412ms/step - accuracy: 0.5812 - loss: 0.6769 - val_accuracy: 0.6531 - val_loss: 0.6681\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389ms/step - accuracy: 0.6072 - loss: 0.6667 - val_accuracy: 0.2562 - val_loss: 0.7919\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - accuracy: 0.5840 - loss: 0.6695 - val_accuracy: 0.3000 - val_loss: 0.7762\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.5939 - loss: 0.6773 - val_accuracy: 0.9250 - val_loss: 0.5998\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.5911 - loss: 0.6765 - val_accuracy: 0.6469 - val_loss: 0.6673\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 415ms/step - accuracy: 0.6225 - loss: 0.6665 - val_accuracy: 0.5063 - val_loss: 0.7076\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 393ms/step - accuracy: 0.6015 - loss: 0.6648 - val_accuracy: 0.4266 - val_loss: 0.7446\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.6157 - loss: 0.6542 - val_accuracy: 0.3578 - val_loss: 0.7610\n",
      "\n",
      "Round 3 Results:\n",
      "Validation Accuracy: 0.6029\n",
      "Validation AUC: 0.6603\n",
      "\n",
      "=== Round 4/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.5971 - loss: 0.6676 - val_accuracy: 0.8469 - val_loss: 0.5807\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.6228 - loss: 0.6596 - val_accuracy: 0.1203 - val_loss: 0.9336\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 415ms/step - accuracy: 0.5541 - loss: 0.6764 - val_accuracy: 0.5250 - val_loss: 0.7108\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389ms/step - accuracy: 0.6315 - loss: 0.6545 - val_accuracy: 0.3297 - val_loss: 0.8271\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.6047 - loss: 0.6588 - val_accuracy: 0.4297 - val_loss: 0.7268\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.5672 - loss: 0.6710 - val_accuracy: 0.5469 - val_loss: 0.6950\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426ms/step - accuracy: 0.5782 - loss: 0.6591 - val_accuracy: 0.5953 - val_loss: 0.6866\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 416ms/step - accuracy: 0.6114 - loss: 0.6574 - val_accuracy: 0.5828 - val_loss: 0.6819\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 392ms/step - accuracy: 0.6238 - loss: 0.6514 - val_accuracy: 0.4234 - val_loss: 0.7696\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.6139 - loss: 0.6516 - val_accuracy: 0.5125 - val_loss: 0.7061\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 440ms/step - accuracy: 0.5860 - loss: 0.6668 - val_accuracy: 0.5422 - val_loss: 0.6976\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 425ms/step - accuracy: 0.5830 - loss: 0.6693 - val_accuracy: 0.5047 - val_loss: 0.7263\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 415ms/step - accuracy: 0.6109 - loss: 0.6617 - val_accuracy: 0.8109 - val_loss: 0.5825\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 393ms/step - accuracy: 0.6309 - loss: 0.6535 - val_accuracy: 0.5016 - val_loss: 0.7254\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.6728 - loss: 0.6399 - val_accuracy: 0.5078 - val_loss: 0.6993\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.5828 - loss: 0.6683 - val_accuracy: 0.7594 - val_loss: 0.6141\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 420ms/step - accuracy: 0.6206 - loss: 0.6575 - val_accuracy: 0.6094 - val_loss: 0.6804\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6399 - loss: 0.6458 - val_accuracy: 0.6234 - val_loss: 0.6658\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389ms/step - accuracy: 0.5910 - loss: 0.6633 - val_accuracy: 0.6187 - val_loss: 0.6657\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.6600 - loss: 0.6396 - val_accuracy: 0.4313 - val_loss: 0.7317\n",
      "\n",
      "Round 4 Results:\n",
      "Validation Accuracy: 0.6129\n",
      "Validation AUC: 0.6677\n",
      "\n",
      "=== Round 5/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.6345 - loss: 0.6461 - val_accuracy: 0.7578 - val_loss: 0.5942\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 422ms/step - accuracy: 0.6305 - loss: 0.6466 - val_accuracy: 0.6891 - val_loss: 0.6450\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6298 - loss: 0.6501 - val_accuracy: 0.6016 - val_loss: 0.6751\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 390ms/step - accuracy: 0.6399 - loss: 0.6414 - val_accuracy: 0.7516 - val_loss: 0.5990\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - accuracy: 0.6161 - loss: 0.6482 - val_accuracy: 0.4047 - val_loss: 0.7541\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 462ms/step - accuracy: 0.6049 - loss: 0.6582 - val_accuracy: 0.6953 - val_loss: 0.6330\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 441ms/step - accuracy: 0.6413 - loss: 0.6438 - val_accuracy: 0.7500 - val_loss: 0.6068\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 432ms/step - accuracy: 0.6276 - loss: 0.6529 - val_accuracy: 0.7578 - val_loss: 0.5948\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 396ms/step - accuracy: 0.6246 - loss: 0.6369 - val_accuracy: 0.4563 - val_loss: 0.7492\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 340ms/step - accuracy: 0.6253 - loss: 0.6577 - val_accuracy: 0.6594 - val_loss: 0.6470\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 0.6346 - loss: 0.6412 - val_accuracy: 0.6938 - val_loss: 0.6301\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 428ms/step - accuracy: 0.6087 - loss: 0.6584 - val_accuracy: 0.4359 - val_loss: 0.7853\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 416ms/step - accuracy: 0.6082 - loss: 0.6527 - val_accuracy: 0.6844 - val_loss: 0.6375\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 390ms/step - accuracy: 0.6202 - loss: 0.6488 - val_accuracy: 0.6500 - val_loss: 0.6390\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.6314 - loss: 0.6426 - val_accuracy: 0.3734 - val_loss: 0.7851\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 440ms/step - accuracy: 0.6062 - loss: 0.6564 - val_accuracy: 0.4531 - val_loss: 0.7654\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 427ms/step - accuracy: 0.6068 - loss: 0.6588 - val_accuracy: 0.4797 - val_loss: 0.7661\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 417ms/step - accuracy: 0.6256 - loss: 0.6417 - val_accuracy: 0.5000 - val_loss: 0.7299\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 390ms/step - accuracy: 0.6322 - loss: 0.6467 - val_accuracy: 0.5406 - val_loss: 0.7193\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - accuracy: 0.6397 - loss: 0.6383 - val_accuracy: 0.5891 - val_loss: 0.6691\n",
      "\n",
      "Round 5 Results:\n",
      "Validation Accuracy: 0.6171\n",
      "Validation AUC: 0.6761\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Demented       0.64      0.49      0.55      2745\n",
      "Non Demented       0.59      0.72      0.65      2745\n",
      "\n",
      "    accuracy                           0.61      5490\n",
      "   macro avg       0.61      0.61      0.60      5490\n",
      "weighted avg       0.61      0.61      0.60      5490\n",
      "\n",
      "\n",
      "=== Round 6/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.6170 - loss: 0.6444 - val_accuracy: 0.5437 - val_loss: 0.7223\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.6240 - loss: 0.6422 - val_accuracy: 0.6219 - val_loss: 0.6748\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6531 - loss: 0.6296 - val_accuracy: 0.8938 - val_loss: 0.5059\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389ms/step - accuracy: 0.6461 - loss: 0.6342 - val_accuracy: 0.4172 - val_loss: 0.8070\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.6361 - loss: 0.6364 - val_accuracy: 0.5281 - val_loss: 0.6984\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.5864 - loss: 0.6629 - val_accuracy: 0.5297 - val_loss: 0.7328\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426ms/step - accuracy: 0.6438 - loss: 0.6457 - val_accuracy: 0.5641 - val_loss: 0.7071\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6719 - loss: 0.6226 - val_accuracy: 0.7516 - val_loss: 0.5986\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 391ms/step - accuracy: 0.6239 - loss: 0.6467 - val_accuracy: 0.5859 - val_loss: 0.6950\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.6203 - loss: 0.6431 - val_accuracy: 0.3344 - val_loss: 0.8007\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.6298 - loss: 0.6462 - val_accuracy: 0.7734 - val_loss: 0.5737\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 427ms/step - accuracy: 0.6364 - loss: 0.6401 - val_accuracy: 0.6484 - val_loss: 0.6556\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 416ms/step - accuracy: 0.6541 - loss: 0.6243 - val_accuracy: 0.7703 - val_loss: 0.5728\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - accuracy: 0.6279 - loss: 0.6379 - val_accuracy: 0.6391 - val_loss: 0.6581\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.6489 - loss: 0.6251 - val_accuracy: 0.5406 - val_loss: 0.6874\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 448ms/step - accuracy: 0.6266 - loss: 0.6454 - val_accuracy: 0.6438 - val_loss: 0.6657\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.6759 - loss: 0.6252 - val_accuracy: 0.6906 - val_loss: 0.6363\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 418ms/step - accuracy: 0.6506 - loss: 0.6293 - val_accuracy: 0.8297 - val_loss: 0.5395\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 394ms/step - accuracy: 0.6363 - loss: 0.6361 - val_accuracy: 0.5766 - val_loss: 0.7033\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.6429 - loss: 0.6399 - val_accuracy: 0.5469 - val_loss: 0.6938\n",
      "\n",
      "Round 6 Results:\n",
      "Validation Accuracy: 0.6160\n",
      "Validation AUC: 0.6829\n",
      "\n",
      "=== Round 7/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 0.6473 - loss: 0.6360 - val_accuracy: 0.5766 - val_loss: 0.7070\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 0.6520 - loss: 0.6263 - val_accuracy: 0.4516 - val_loss: 0.8087\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6500 - loss: 0.6224 - val_accuracy: 0.7547 - val_loss: 0.5854\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.6708 - loss: 0.6266 - val_accuracy: 0.5531 - val_loss: 0.7300\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.6752 - loss: 0.6223 - val_accuracy: 0.3500 - val_loss: 0.8238\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 448ms/step - accuracy: 0.6656 - loss: 0.6240 - val_accuracy: 0.7016 - val_loss: 0.6204\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426ms/step - accuracy: 0.6550 - loss: 0.6313 - val_accuracy: 0.5891 - val_loss: 0.7113\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 419ms/step - accuracy: 0.6458 - loss: 0.6284 - val_accuracy: 0.7734 - val_loss: 0.5801\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 394ms/step - accuracy: 0.6427 - loss: 0.6322 - val_accuracy: 0.5578 - val_loss: 0.7202\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.6555 - loss: 0.6201 - val_accuracy: 0.4516 - val_loss: 0.7587\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 472ms/step - accuracy: 0.6646 - loss: 0.6249 - val_accuracy: 0.8344 - val_loss: 0.5387\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 458ms/step - accuracy: 0.6563 - loss: 0.6269 - val_accuracy: 0.5609 - val_loss: 0.7313\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 576ms/step - accuracy: 0.6255 - loss: 0.6337 - val_accuracy: 0.6984 - val_loss: 0.6270\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 523ms/step - accuracy: 0.6914 - loss: 0.6007 - val_accuracy: 0.5250 - val_loss: 0.7435\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 433ms/step - accuracy: 0.6660 - loss: 0.6191 - val_accuracy: 0.4328 - val_loss: 0.7732\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 656ms/step - accuracy: 0.6653 - loss: 0.6253 - val_accuracy: 0.8734 - val_loss: 0.5059\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 612ms/step - accuracy: 0.6403 - loss: 0.6343 - val_accuracy: 0.5953 - val_loss: 0.6954\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 546ms/step - accuracy: 0.6307 - loss: 0.6483 - val_accuracy: 0.9516 - val_loss: 0.4352\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 490ms/step - accuracy: 0.6316 - loss: 0.6482 - val_accuracy: 0.6516 - val_loss: 0.6541\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 428ms/step - accuracy: 0.6779 - loss: 0.6134 - val_accuracy: 0.3688 - val_loss: 0.7954\n",
      "\n",
      "Round 7 Results:\n",
      "Validation Accuracy: 0.6344\n",
      "Validation AUC: 0.6917\n",
      "\n",
      "=== Round 8/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 522ms/step - accuracy: 0.6409 - loss: 0.6333 - val_accuracy: 0.5562 - val_loss: 0.7242\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 547ms/step - accuracy: 0.6541 - loss: 0.6180 - val_accuracy: 0.6250 - val_loss: 0.6636\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 573ms/step - accuracy: 0.6575 - loss: 0.6175 - val_accuracy: 0.6187 - val_loss: 0.6690\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 516ms/step - accuracy: 0.6751 - loss: 0.6117 - val_accuracy: 0.2859 - val_loss: 0.9783\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 417ms/step - accuracy: 0.6601 - loss: 0.6199 - val_accuracy: 0.4219 - val_loss: 0.7791\n",
      "\n",
      "Client 1 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 631ms/step - accuracy: 0.6738 - loss: 0.6066 - val_accuracy: 0.8516 - val_loss: 0.5111\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 603ms/step - accuracy: 0.6584 - loss: 0.6245 - val_accuracy: 0.5109 - val_loss: 0.7648\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 598ms/step - accuracy: 0.6428 - loss: 0.6256 - val_accuracy: 0.6062 - val_loss: 0.6723\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 558ms/step - accuracy: 0.6298 - loss: 0.6348 - val_accuracy: 0.6391 - val_loss: 0.6576\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 439ms/step - accuracy: 0.6675 - loss: 0.6149 - val_accuracy: 0.5641 - val_loss: 0.6901\n",
      "\n",
      "Client 2 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 629ms/step - accuracy: 0.6453 - loss: 0.6295 - val_accuracy: 0.5063 - val_loss: 0.7588\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 529ms/step - accuracy: 0.6487 - loss: 0.6216 - val_accuracy: 0.6500 - val_loss: 0.6546\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 432ms/step - accuracy: 0.6502 - loss: 0.6216 - val_accuracy: 0.8891 - val_loss: 0.4802\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 394ms/step - accuracy: 0.6578 - loss: 0.6191 - val_accuracy: 0.6187 - val_loss: 0.6692\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - accuracy: 0.6474 - loss: 0.6134 - val_accuracy: 0.3922 - val_loss: 0.7972\n",
      "\n",
      "Client 3 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 469ms/step - accuracy: 0.6460 - loss: 0.6259 - val_accuracy: 0.7891 - val_loss: 0.5636\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 432ms/step - accuracy: 0.6866 - loss: 0.6057 - val_accuracy: 0.6281 - val_loss: 0.6753\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 427ms/step - accuracy: 0.6535 - loss: 0.6270 - val_accuracy: 0.8859 - val_loss: 0.4850\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 395ms/step - accuracy: 0.6690 - loss: 0.6184 - val_accuracy: 0.4266 - val_loss: 0.8385\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 373ms/step - accuracy: 0.6529 - loss: 0.6148 - val_accuracy: 0.3187 - val_loss: 0.8774\n",
      "\n",
      "Round 8 Results:\n",
      "Validation Accuracy: 0.6461\n",
      "Validation AUC: 0.7051\n",
      "\n",
      "=== Round 9/10 ===\n",
      "\n",
      "Client 0 Training (Epochs: 5)...\n",
      "Epoch 1/5\n",
      "\u001b[1m34/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 460ms/step - accuracy: 0.6306 - loss: 0.6336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 230\u001b[39m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m global_model\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m# Run with identical output format\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     final_model = \u001b[43mfederated_training_fedbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# Final evaluation (same as FedAvg)\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Final Model Evaluation ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mfederated_training_fedbn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    134\u001b[39m local_model.compile(\n\u001b[32m    135\u001b[39m     optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n\u001b[32m    136\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    137\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    138\u001b[39m )\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Identical training progress as FedAvg\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m history_local = \u001b[43mlocal_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLIENT_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Same as FedAvg (shows Keras progress bar)\u001b[39;49;00m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m client_weights.append(local_model.get_weights())\n\u001b[32m    151\u001b[39m client_samples.append(clients[client_id][\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].samples)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator.enumerate_epoch():\n\u001b[32m    319\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1550\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1560\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1561\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1562\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1567\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "from tqdm.auto import tqdm  # Progress bars\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"C:/Users/musab/PycharmProjects/DataScienceGame/LOHITH_NEW/archive/Data\"\n",
    "CENTRAL_MODEL_PATH = \"central_alzheimer_model(new).keras\"\n",
    "NUM_CLIENTS = 4\n",
    "ROUNDS = 10\n",
    "CLIENT_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS_PER_EPOCH = 50\n",
    "\n",
    "def create_client_datasets():\n",
    "    \"\"\"Create client datasets with same loading style as FedAvg\"\"\"\n",
    "    clients = []\n",
    "    print(\"ğŸ” Loading client datasets...\")\n",
    "    for client_id in range(NUM_CLIENTS):\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        \n",
    "        train_gen = train_datagen.flow_from_directory(\n",
    "            DATA_PATH,\n",
    "            target_size=TARGET_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            seed=42 + client_id\n",
    "        )\n",
    "        \n",
    "        val_gen = train_datagen.flow_from_directory(\n",
    "            DATA_PATH,\n",
    "            target_size=TARGET_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            subset='validation',\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nClient {client_id} Data:\")\n",
    "        print(f\"Training samples: {train_gen.samples}\")\n",
    "        print(f\"Validation samples: {val_gen.samples}\")\n",
    "        print(f\"Class distribution: {train_gen.class_indices}\")\n",
    "        \n",
    "        clients.append({\n",
    "            'train': train_gen,\n",
    "            'val': val_gen,\n",
    "            'train_steps': len(train_gen),\n",
    "            'val_steps': len(val_gen)\n",
    "        })\n",
    "    return clients\n",
    "\n",
    "def create_fedbn_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"Create model with BatchNorm layers for FedBN\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def federated_training_fedbn():\n",
    "    print(\"\\n=== Federated Learning with FedBN ===\")\n",
    "    print(f\"Running {ROUNDS} rounds with {CLIENT_EPOCHS} epochs per client\")\n",
    "    \n",
    "    clients = create_client_datasets()\n",
    "    global_model = create_fedbn_model()\n",
    "    \n",
    "    global_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    # Tracking (same format as FedAvg)\n",
    "    history = {\n",
    "        'round': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_auc': [],\n",
    "        'client_losses': [[] for _ in range(NUM_CLIENTS)],\n",
    "        'client_accuracies': [[] for _ in range(NUM_CLIENTS)]\n",
    "    }\n",
    "    \n",
    "    # Baseline evaluation\n",
    "    baseline_val = global_model.evaluate(clients[0]['val'], verbose=0)\n",
    "    print(f\"\\nBaseline - Accuracy: {baseline_val[1]:.4f}, AUC: {baseline_val[2]:.4f}\")\n",
    "    \n",
    "    # Main training loop with same progress style as FedAvg\n",
    "    for round in range(ROUNDS):\n",
    "        print(f\"\\n=== Round {round+1}/{ROUNDS} ===\")\n",
    "        client_weights = []\n",
    "        client_samples = []\n",
    "        \n",
    "        # Client training with identical progress display\n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            print(f\"\\nClient {client_id} Training (Epochs: {CLIENT_EPOCHS})...\")\n",
    "            local_model = clone_model(global_model)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            \n",
    "            # Freeze BN layers for FedBN\n",
    "            for layer in local_model.layers:\n",
    "                if isinstance(layer, BatchNormalization):\n",
    "                    layer.trainable = False\n",
    "            \n",
    "            local_model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Identical training progress as FedAvg\n",
    "            history_local = local_model.fit(\n",
    "                clients[client_id]['train'],\n",
    "                steps_per_epoch=min(STEPS_PER_EPOCH, clients[client_id]['train_steps']),\n",
    "                epochs=CLIENT_EPOCHS,\n",
    "                verbose=1,  # Same as FedAvg (shows Keras progress bar)\n",
    "                validation_data=clients[client_id]['val'],\n",
    "                validation_steps=min(20, clients[client_id]['val_steps'])\n",
    "            )\n",
    "            \n",
    "            client_weights.append(local_model.get_weights())\n",
    "            client_samples.append(clients[client_id]['train'].samples)\n",
    "            history['client_losses'][client_id].append(history_local.history['loss'][-1])\n",
    "            history['client_accuracies'][client_id].append(history_local.history['accuracy'][-1])\n",
    "            \n",
    "            del local_model\n",
    "            gc.collect()\n",
    "        \n",
    "        # FedBN aggregation (skip BN layers)\n",
    "        global_weights = global_model.get_weights()\n",
    "        for i in range(len(global_weights)):\n",
    "            layer_idx = i // 2  # Determine which layer these weights belong to\n",
    "            if not isinstance(global_model.layers[layer_idx], BatchNormalization):\n",
    "                global_weights[i] = np.average(\n",
    "                    [weights[i] for weights in client_weights],\n",
    "                    axis=0,\n",
    "                    weights=client_samples\n",
    "                )\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # Evaluation (same format as FedAvg)\n",
    "        val_results = global_model.evaluate(clients[0]['val'], verbose=0)\n",
    "        history['round'].append(round)\n",
    "        history['val_accuracy'].append(val_results[1])\n",
    "        history['val_auc'].append(val_results[2])\n",
    "        \n",
    "        print(f\"\\nRound {round+1} Results:\")\n",
    "        print(f\"Validation Accuracy: {val_results[1]:.4f}\")\n",
    "        print(f\"Validation AUC: {val_results[2]:.4f}\")\n",
    "        \n",
    "        # Periodic full evaluation (same as FedAvg)\n",
    "        if (round+1) % 5 == 0:\n",
    "            val_gen = clients[0]['val']\n",
    "            val_gen.reset()\n",
    "            y_pred = (global_model.predict(val_gen, verbose=0) > 0.5).astype(int)\n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(classification_report(val_gen.labels, y_pred, \n",
    "                                      target_names=val_gen.class_indices.keys()))\n",
    "    \n",
    "    # Save final model in same format\n",
    "    global_model.save('alzheimer_model_fedbn_4Clients.keras')\n",
    "    print(\"\\nğŸ’¾ Model saved as 'alzheimer_model_fedbn_4Clients.keras'\")\n",
    "    \n",
    "    # Identical visualization to FedAvg\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['round'], history['val_accuracy'], 'b-o', label='Accuracy')\n",
    "    plt.plot(history['round'], history['val_auc'], 'r-s', label='AUC')\n",
    "    plt.title('Global Model Performance')\n",
    "    plt.xlabel('Federation Round')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    for client_id in range(NUM_CLIENTS):\n",
    "        plt.plot(history['round'], history['client_accuracies'][client_id], \n",
    "                label=f'Client {client_id}')\n",
    "    plt.title('Client Training Accuracies')\n",
    "    plt.xlabel('Federation Round')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    for client_id in range(NUM_CLIENTS):\n",
    "        plt.plot(history['round'], history['client_losses'][client_id],\n",
    "                label=f'Client {client_id}')\n",
    "    plt.title('Client Training Losses')\n",
    "    plt.xlabel('Federation Round')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fedbn_training_progress.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return global_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run with identical output format\n",
    "    final_model = federated_training_fedbn()\n",
    "    \n",
    "    # Final evaluation (same as FedAvg)\n",
    "    print(\"\\n=== Final Model Evaluation ===\")\n",
    "    print(\"Model ready for deployment with:\")\n",
    "    print(f\"- {ROUNDS} federation rounds\")\n",
    "    print(f\"- {CLIENT_EPOCHS} epochs per client\")\n",
    "    print(f\"- {NUM_CLIENTS} participating clients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f94ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading model...\n",
      "âœ… Model loaded!\n",
      "Found 5490 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Predicting...\n",
      "\u001b[1m172/172\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step\n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Demented       0.63      0.94      0.75      2745\n",
      "Non Demented       0.89      0.44      0.58      2745\n",
      "\n",
      "    accuracy                           0.69      5490\n",
      "   macro avg       0.76      0.69      0.67      5490\n",
      "weighted avg       0.76      0.69      0.67      5490\n",
      "\n",
      "\n",
      "ğŸ“ˆ ROC AUC Score: 0.7719667817956809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musab\\AppData\\Local\\Temp\\ipykernel_27440\\2886854659.py:73: UserWarning: Glyph 129504 (\\N{BRAIN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "c:\\Users\\musab\\PycharmProjects\\DataScienceGame\\.venv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 129504 (\\N{BRAIN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ===============================\n",
    "# Configs\n",
    "# ===============================\n",
    "MODEL_PATH = \"alzheimer_model_fedbn_4Clients.keras\"\n",
    "DATA_PATH = \"C:/Users/musab/PycharmProjects/DataScienceGame/LOHITH_NEW/archive/Data\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "# ===============================\n",
    "# 1. Load the model\n",
    "# ===============================\n",
    "print(\"ğŸ“¦ Loading model...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# (Optional but recommended) Recompile to restore metrics if needed\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "print(\"âœ… Model loaded!\")\n",
    "\n",
    "# ===============================\n",
    "# 2. Prepare validation data\n",
    "# ===============================\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,   # Important for correct prediction-label alignment\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 3. Make predictions\n",
    "# ===============================\n",
    "print(\"ğŸ” Predicting...\")\n",
    "pred_probs = model.predict(val_gen)\n",
    "preds = (pred_probs > 0.5).astype(int).flatten()\n",
    "y_true = val_gen.classes\n",
    "\n",
    "# ===============================\n",
    "# 4. Evaluation Metrics\n",
    "# ===============================\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_true, preds, target_names=list(val_gen.class_indices.keys())))\n",
    "\n",
    "print(\"\\nğŸ“ˆ ROC AUC Score:\", roc_auc_score(y_true, pred_probs))\n",
    "\n",
    "# ===============================\n",
    "# 5. Confusion Matrix\n",
    "# ===============================\n",
    "cm = confusion_matrix(y_true, preds)\n",
    "labels = list(val_gen.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"ğŸ§  Confusion Matrix - Alzheimer's Detection\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
